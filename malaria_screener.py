# -*- coding: utf-8 -*-
"""Copy of Malaria Screener.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17-J7L4RJLdUnysoVpqNa4Xqt71VQIvAb

# **Malaria Cell Detection using CNN**
[Malaria cell](https://lhncbc.nlm.nih.gov/LHC-downloads/downloads.html#malaria-datasets) detection using cnn.<br>
<img src="https://camo.githubusercontent.com/2716ac3884cd0e4743cc59e5b8e0ba4d31cf45114ea318d370b132e8a40e0af6/68747470733a2f2f7777772e7079696d6167657365617263682e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f31322f646c5f6d65646963616c5f696d6167696e675f6d616c617269615f646174617365742e6a7067"  >

### Importing the libraries
"""

import tensorflow as tf
# image processing submodule ImageDataGenerator
from keras.preprocessing.image import ImageDataGenerator

# check the version of tensorflow if it's upated and compatible
tf.__version__

"""## Part 0 - Load Data"""

!unzip -q cell_images.zip -d /content

"""## Part 1 - Data Preprocessing

### Preprocessing the Training set
"""

# creation of tranformation of the training dataset object 'train_datagen'
train_datagen = ImageDataGenerator(
        # feature scaling
        rescale=1./255,  
        # image augementation to prevent overfitting
        shear_range=0.2,  
        zoom_range=0.2,
        horizontal_flip=True)

# connect train_datagen object and import training dataset/images
training_set = train_datagen.flow_from_directory(
        '/content/cell_images/train',
        # resize and create batches to make the computation less intensive
        target_size=(64, 64), # 64x64 for faster computation
        batch_size=32, # 32 images in each batch
        # set class mode to binary
        class_mode='binary')

"""### Preprocessing the Test set"""

# feature scale test dataset and not transform
test_datagen = ImageDataGenerator(rescale=1./255)
test_set = test_datagen.flow_from_directory(
        '/content/cell_images/test',
        # resize and create batches to make the computation less intensive
        target_size=(64, 64), # 64x64 for faster computation
        batch_size=32, # 32 images in each batch
        # set class mode to binary
        class_mode='binary')

"""## Part 2 - Model Building the CNN

### Initialising the CNN
"""

# instantiate the cnn model
cmodel = tf.keras.models.Sequential()

"""### Step 1 - Convolution"""

from warnings import filters
# add first convolution layer
"""set parameters:
     filters, kernel_size, activation, input_shape
      
    ReLU: in hidden layer to avoid vanishing gradient 
    problem and better computation performance.
"""
# result will be the feature map
cmodel.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))

"""### Step 2 - Pooling"""

# add first pooling layer
"""
  set parameters: pool_size,  strides
"""
# we stride by 2 since we want the max for each square
# extra padding can be added around the pooling that contain zero values
cmodel.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))

"""### Adding a second convolutional layer"""

"""
We add a second convolutional layer 
and ommit the input_shape parameter
that is import at the first stage
"""
cmodel.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))
# second pooling layer
cmodel.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))

"""### Step 3 - Flattening"""

# create and flatten into one dimension vector
cmodel.add(tf.keras.layers.Flatten())

"""### Step 4 - Full Connection"""

# fully connected layer
"""
 add a dense layer of 128 and 64 units to get a better accuracy
 and a relu activation function since we're yet to reach
 the final output layer.
"""
cmodel.add(tf.keras.layers.Dense(units=128, activation='relu'))

"""### Step 5 - Output Layer"""

# OUTPUT LAYER
"""One neuron per class for our classification
   and a sigmoid activation function which is suitable
   for binary class.
"""
cmodel.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

"""#### - **Model summary**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # An insight about the model
# cmodel.summary()

"""## Part 3 - Training the CNN

### Compiling the CNN
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# """
#    Binary cross-entropy: is used when true labels are 
#                             one-hot encoded.
#    Cross entropy loss: is a metric used to measure how well 
#    a classification model in machine learning performs
#    keras.io/metric
# """
# cmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

"""### Training the CNN on the Training set and evaluating it on the Test set

**callbacks**: a callback is an object (method) that can perform actions at various stages of training (*e.g.* at the start or end of an epoch, before or after a single batch, etc).
"""

# Check computational time in seconds
import time

# get the start time
st = time.time()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# """
# training and evaluating the model at the
# same time. using the preprocessed training and validation
# epoch: the amount of time a data is passed in the network
# """
# epochs = 30
# 
# callbacks = [
#     # to save the model after every epoch
#     # keras.callbacks.ModelCheckpoint("save_at_{epoch}.h50"),
#     # logging
#     tf.keras.callbacks.TensorBoard(log_dir="logs", write_graph=True, write_images=False, update_freq="epoch",)
# ]
# 
# cmodel.fit(x = training_set, validation_data = test_set, epochs = epochs, callbacks=callbacks)

"""#### **Computational time**"""

# get the end time
et = time.time()

# get the execution time
elapsed_time = et - st
print('Execution time:', elapsed_time, 'seconds')
print('Execution time:', elapsed_time/60, 'minutes')
print('Execution time:', elapsed_time/(60*60), 'hours')

"""#### **Save the model using pickle**"""

import pickle

# save the model to disk
filename = 'malaria_final.sav'
pickle.dump(cmodel, open(filename, 'wb'))
 
# some time later...
 
# load the model from disk
#loaded_model = pickle.load(open(filename, 'rb'))
#result = loaded_model.score(X_test, Y_test)
#print(result)

"""## Part 4 - Model Evaluation"""

cmodel.history.history

# lets explore our metrics a bit
import pandas as pd
Metrics = pd.DataFrame(cmodel.history.history)

Metrics

# let us see our loss and validation loss 
Metrics[["loss","val_loss"]].plot();

# let us see our accuracy and validation accuracy
Metrics[["accuracy","val_accuracy"]].plot()

"""load the **TensorBoard** module (provided with Tensorflow) to see our line plots!"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard
# %tensorboard --logdir logs

"""## Part 5 - Making a single prediction"""

import numpy as np
from keras.preprocessing import image

# load image from path
test_image = tf.keras.utils.load_img('/content/cell_images/test/parasitized/C101P62ThinF_IMG_20150918_151335_cell_58.png', target_size=(64, 64))
# convert to numpy array                               
test_image = tf.keras.utils.img_to_array(test_image)
# expand so it correspond to the batch
test_image = np.expand_dims(test_image, axis = 0)
# predict the image
result = cmodel.predict(test_image)

# get the total class and indices
training_set.class_indices

# Use conditional statements
if result[0][0] == 1.:
  prediction = "uninfected"
else:
  prediction = "parasitized"

print("It's a ", prediction," cell.")

# Commented out IPython magic to ensure Python compatibility.
# output the preditcted imaage
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img = mpimg.imread('/content/cell_images/test/parasitized/C101P62ThinF_IMG_20150918_151335_cell_58.png')
imgplot = plt.imshow(img)
plt.show();